{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższe komórki powinny być odpalone zawsze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.metrics import jaccard_similarity_score as jaccard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "typesinput = {\n",
    "    'itemID': np.dtype(int),\n",
    "    'categoryID': np.dtype(int),\n",
    "    'title': np.dtype(str),\n",
    "    'description': np.dtype(str),\n",
    "    'images_array': np.dtype(str),\n",
    "    'attrsJSON': np.dtype(str),\n",
    "    'price': np.dtype(float),\n",
    "    'locationID': np.dtype(int),\n",
    "    'metroID': np.dtype(float),\n",
    "    'lat': np.dtype(float),\n",
    "    'lon': np.dtype(float),\n",
    "}\n",
    "\n",
    "types1 = {\n",
    "        'itemID_1': np.dtype(int),\n",
    "        'itemID_2': np.dtype(int),\n",
    "        'isDuplicate': np.dtype(int),\n",
    "        'generationMethod': np.dtype(int),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_similarity_and_save(similarity_function, tfidf_file, pairs, itemstest, output_name):\n",
    "\n",
    "    tfidfs_desc = pickle.load(open(\"tfidfs/\" + tfidf_file,\"r\"))\n",
    "        \n",
    "    def cosine_sim(itemid1, itemid2):\n",
    "        return cosine(tfidfs_desc[itemid1], tfidfs_desc[itemid2])\n",
    "\n",
    "    def jaccard_sim(itemid1, itemid2):\n",
    "        return jaccard(tfidfs_desc[itemid1], tfidfs_desc[itemid2])\n",
    "\n",
    "    index_ = pd.Index(itemstest.itemID)\n",
    "    pairs.itemID_1 = pairs.apply(lambda x: index_.get_loc(x['itemID_1']), axis=1)\n",
    "    pairs.itemID_2 = pairs.apply(lambda x: index_.get_loc(x['itemID_2']), axis=1)\n",
    "\n",
    "    if similarity_function==\"cosine_sim\":\n",
    "        vecfunc = np.vectorize(cosine_sim)\n",
    "    elif similarity_function==\"jaccard_sim\":\n",
    "        vecfunc = np.vectorize(jaccard_sim)\n",
    "    res = vecfunc(pairs['itemID_1'], pairs['itemID_2'])\n",
    "    \n",
    "    train_simil = pd.Series(res)\n",
    "    train_simil.to_csv(\"similarities/\" + output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCRIPTION TF-IDFS\n",
    "\n",
    "Generacja TF-IDF dla opisów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "items = pd.read_csv(\"input/ItemInfo_train.csv\", dtype=typesinput, usecols=['description'])\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['description'])\n",
    "items.fillna(\"\", inplace=True)\n",
    "itemstest.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sprawdz tf-idf bez stopwordsow\n",
    "tfidf = TfidfVectorizer(stop_words = stopwords.words('russian')).fit(pd.concat([items.description, itemstest.description]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transf = tfidf.transform(items.description)\n",
    "pickle.dump(transf, open(\"tfidfs/description_stopwords_train.data\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf = tfidf.transform(itemstest.description)\n",
    "pickle.dump(transf, open(\"tfidfs/description_stopwords_test.data\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITLE TF-IDFS\n",
    "\n",
    "Generacja TF-IDF dla tytułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "items = pd.read_csv(\"input/ItemInfo_train.csv\", dtype=typesinput, usecols=['title'])\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['title'])\n",
    "items.fillna(\"\", inplace=True)\n",
    "itemstest.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(stop_words = stopwords.words('russian')).fit(pd.concat([items.title, itemstest.title]))\n",
    "transf = tfidf.transform(items.title)\n",
    "pickle.dump(transf, open(\"tfidfs/title_stopwords_train.data\",\"w\"))\n",
    "transf = tfidf.transform(itemstest.title)\n",
    "pickle.dump(transf, open(\"tfidfs/title_stopwords_test.data\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer().fit(pd.concat([items.title, itemstest.title]))\n",
    "transf = tfidf.transform(items.title)\n",
    "pickle.dump(transf, open(\"tfidfs/title_train.data\",\"w\"))\n",
    "transf = tfidf.transform(itemstest.title)\n",
    "pickle.dump(transf, open(\"tfidfs/title_test.data\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGES TF-IDFS\n",
    "\n",
    "Generacja TF-IDF dla oznaczen obrazkow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_tfidf_limit = 2000000 # Reszta się będzie mniej więcej powtarzać.\n",
    "\n",
    "dataset = pd.read_csv('input/labels/labels_merged.csv', usecols=['labels'])\n",
    "dataset.fillna(\"\", inplace=True)\n",
    "\n",
    "wordlist = []\n",
    "\n",
    "for i, row in enumerate(dataset.values):\n",
    "    if i > 0 and i % 50000 == 0:\n",
    "        print \"step \" + str(i)\n",
    "    if i > 0 and i % images_tfidf_limit == 0:\n",
    "        break\n",
    "    for wordp in str(row).split(';'):\n",
    "        wordf = wordp.split(':')[1]\n",
    "        for word in wordf.split(','):\n",
    "            if len(word) == 0:\n",
    "                continue\n",
    "            if len(word) >= 2 and word[len(word)-1] == ']':\n",
    "                word = word[:-2]\n",
    "            wordlist.append(word.lower())\n",
    "\n",
    "#print wordlist\n",
    "\n",
    "print \"processed \" + str(len(wordlist))\n",
    "print \"vectorizing... \"\n",
    "\n",
    "tfidf = TfidfVectorizer().fit(wordlist)\n",
    "pickle.dump(tfidf, open('tfidfs/image.data', 'w'))\n",
    "\n",
    "print \"vectorization done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wczytywanie...\n",
      "wczytane.\n",
      "przetwarzanie...\n",
      "43.2824878693\n"
     ]
    }
   ],
   "source": [
    "# Generacja podobieństwa dla par - zbiór treningowy\n",
    "\n",
    "print 'wczytywanie...'\n",
    "pairs = pd.read_csv(\"input/ItemPairs_train.csv\", dtype=types1)\n",
    "tfidfs = pickle.load(open(\"tfidfs/image.data\",\"r\"))\n",
    "df = pd.read_csv(\"input/ItemInfo_train.csv\", dtype=typesinput, usecols=['itemID', 'images_array'])\n",
    "label_df = pd.read_csv('input/labels/labels_merged.csv', usecols=['id', 'labels'])\n",
    "label_df.fillna(\"\", inplace=True)\n",
    "\n",
    "def get_labelstring(raw):\n",
    "    wordlist = []\n",
    "    for wordp in str(raw).split(';'):\n",
    "        wordf = wordp.split(':')[1]\n",
    "        for word in wordf.split(','):\n",
    "            if len(word) == 0:\n",
    "                continue\n",
    "            if len(word) >= 2 and word[len(word)-1] == ']':\n",
    "                word = word[:-2]\n",
    "            wordlist.append(word.lower())\n",
    "    return ','.join(wordlist)\n",
    "\n",
    "def get_label_string(idn):\n",
    "    string = \"\"\n",
    "    arr1 = df.loc[df['itemID'] == idn]['images_array']\n",
    "    if \"nan\" != str(arr1.tolist()[0]):\n",
    "        for elem in arr1.tolist()[0].split(','):\n",
    "            label = label_df.loc[label_df['id'] == int(elem)]['labels']\n",
    "            raw = label.tolist()[0]\n",
    "            string += get_labelstring(raw)\n",
    "        return string\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def get_cosine(id1, id2):\n",
    "    stringa = get_label_string(id1)\n",
    "    stringb = get_label_string(id2)\n",
    "\n",
    "    veca = tfidfs.transform([stringa])[0]\n",
    "    vecb = tfidfs.transform([stringb])[0]\n",
    "    return cosine(veca, vecb)\n",
    "\n",
    "def processInput(val):\n",
    "    i, row = val\n",
    "    id1 = row[0]\n",
    "    id2 = row[1]\n",
    "    return get_cosine(id1, id2)\n",
    "\n",
    "# Łączenie tablic par i list obrazków\n",
    "df_left = df.rename(columns={'images_array': 'images_array_1'})\n",
    "df_right = df.rename(columns={'images_array': 'images_array_2'})\n",
    "pairs_1 = pd.merge(pairs, df_left, how='left', left_on='itemID_1', right_on='itemID', left_index=True)\n",
    "pairs_12 = pd.merge(pairs_1, df_right, how='left', left_on='itemID_2', right_on='itemID', left_index=True)\n",
    "print 'wczytane.'\n",
    "\n",
    "# To jest zdecydowanie za wolne, trzeba jakoś przyśpieszyć\n",
    "print 'przetwarzanie...'\n",
    "inputs = enumerate(pairs_12.head(1000).values)\n",
    "num_cores = multiprocessing.cpu_count()-1\n",
    "start = time.time()\n",
    "results = Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in inputs)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "#results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COSINE \n",
    "\n",
    "Liczenie podobieństwa cosinusowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pairs = pd.read_csv(\"input/ItemPairs_test.csv\", dtype=types1)\n",
    "tfidfs_desc = pickle.load(open(\"tfidfs/description_stopwords_test.data\",\"r\"))\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_ = pd.Index(itemstest.itemID)\n",
    "pairs.itemID_1 = pairs.apply(lambda x: index_.get_loc(x['itemID_1']), axis=1)\n",
    "pairs.itemID_2 = pairs.apply(lambda x: index_.get_loc(x['itemID_2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_simil = pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_simil.to_csv(\"similarities/test_description_stopwords_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"input/ItemPairs_train.csv\", dtype=types1)\n",
    "tfidfs_desc = pickle.load(open(\"tfidfs/description_stopwords_train.data\",\"r\"))\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_train.csv\", dtype=typesinput, usecols=['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_ = pd.Index(itemstest.itemID)\n",
    "pairs.itemID_1 = pairs.apply(lambda x: index_.get_loc(x['itemID_1']), axis=1)\n",
    "pairs.itemID_2 = pairs.apply(lambda x: index_.get_loc(x['itemID_2']), axis=1)\n",
    "\n",
    "vecfunc = np.vectorize(cosine_sim)\n",
    "res = vecfunc(pairs['itemID_1'], pairs['itemID_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_simil = pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_simil.to_csv(\"similarities/train_description_stopwords_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COSINE TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pairs = pd.read_csv(\"input/ItemPairs_test.csv\", dtype=types1)\n",
    "tfidfs_desc = pickle.load(open(\"tfidfs/title_stopwords_train.data\",\"r\"))\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_ = pd.Index(itemstest.itemID)\n",
    "pairs.itemID_1 = pairs.apply(lambda x: index_.get_loc(x['itemID_1']), axis=1)\n",
    "pairs.itemID_2 = pairs.apply(lambda x: index_.get_loc(x['itemID_2']), axis=1)\n",
    "\n",
    "# Da się zrównoleglić\n",
    "\n",
    "vecfunc = np.vectorize(cosine_sim)\n",
    "res = vecfunc(pairs['itemID_1'], pairs['itemID_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_simil = pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_simil.to_csv(\"similarities/test_title_stopwords_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"input/ItemPairs_train.csv\", dtype=types1)\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_train.csv\", dtype=typesinput, usecols=['itemID'])\n",
    "# compute_similarity_and_save(\"cosine_sim\", \"title_stopwords_train.data\", pairs, itemstest, \"train_title_stopwords_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_similarity_and_save(\"cosine_sim\", \"title_train.data\", pairs, itemstest, \"train_title_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_similarity_and_save(\"jaccard_sim\", \"title_train.data\", pairs, itemstest, \"train_title_jaccard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_similarity_and_save(\"jaccard_sim\", \"title_stopwords_train.data\", pairs, itemstest, \"train_title_stopwords_jaccard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"input/ItemPairs_test.csv\", dtype=types1)\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['itemID'])\n",
    "compute_similarity_and_save(\"cosine_sim\", \"title_stopwords_test.data\", pairs, itemstest, \"test_title_stopwords_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"input/ItemPairs_test.csv\", dtype=types1)\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['itemID'])\n",
    "compute_similarity_and_save(\"cosine_sim\", \"title_test.data\", pairs, itemstest, \"test_title_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"input/ItemPairs_test.csv\", dtype=types1)\n",
    "itemstest = pd.read_csv(\"input/ItemInfo_test.csv\", dtype=typesinput, usecols=['itemID'])\n",
    "compute_similarity_and_save(\"jaccard_sim\", \"title_test.data\", pairs, itemstest, \"test_title_jaccard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"input/ItemPairs_test.csv\", dtype=types1)\n",
    "compute_similarity_and_save(\"jaccard_sim\", \"title_stopwords_test.data\", pairs, itemstest, \"tessttitle_stopwords_jaccard.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
