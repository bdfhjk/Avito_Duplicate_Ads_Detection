{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy as gp\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import zipfile\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "random.seed(2016)\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values)\n",
    "    testval = list(test.columns.values)\n",
    "    output = intersect(trainval, testval)\n",
    "    output.remove('itemID_1')\n",
    "    output.remove('itemID_2')\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n",
    "\n",
    "def print_features_importance(imp):\n",
    "    for i in range(len(imp)):\n",
    "        print(\"# \" + str(imp[i][1]))\n",
    "        print('output.remove(\\'' + imp[i][0] + '\\')')\n",
    "\n",
    "\n",
    "def run_default_test(train, test, features, target, random_state=0):\n",
    "    eta = 0.1\n",
    "    max_depth = 5\n",
    "    subsample = 0.8\n",
    "    colsample_bytree = 0.8\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state\n",
    "    }\n",
    "    num_boost_round = 300\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.1\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_ntree_limit)\n",
    "    score = roc_auc_score(X_valid[target].values, check)\n",
    "    print('Check error value: {:.6f}'.format(score))\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_ntree_limit)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score\n",
    "\n",
    "\n",
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('id,probability\\n')\n",
    "    total = 0\n",
    "    for id in test['id']:\n",
    "        str1 = str(id) + ',' + str(prediction[total])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n",
    "\n",
    "    # print('Creating zip-file...')\n",
    "    # z = zipfile.ZipFile(sub_file + \".zip\", \"w\", zipfile.ZIP_DEFLATED)\n",
    "    # z.write(sub_file)\n",
    "    # z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test_train():\n",
    "    \n",
    "    # A version without preprocessing\n",
    "\n",
    "    train = pd.read_csv('input/train_merged.csv')\n",
    "    test = pd.read_csv('input/test_merged.csv')\n",
    "    \n",
    "    features = get_features(train, test)\n",
    "    return train, test, features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost params. ETA: 0.1, MAX_DEPTH: 5, SUBSAMPLE: 0.8, COLSAMPLE_BY_TREE: 0.8\n",
      "Will train until eval error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-auc:0.726801\teval-auc:0.726486\n",
      "[1]\ttrain-auc:0.735297\teval-auc:0.734875\n",
      "[2]\ttrain-auc:0.751493\teval-auc:0.751567\n",
      "[3]\ttrain-auc:0.750622\teval-auc:0.750656\n",
      "[4]\ttrain-auc:0.755380\teval-auc:0.755278\n",
      "[5]\ttrain-auc:0.756313\teval-auc:0.756266\n",
      "[6]\ttrain-auc:0.757541\teval-auc:0.757354\n",
      "[7]\ttrain-auc:0.759855\teval-auc:0.759600\n",
      "[8]\ttrain-auc:0.763878\teval-auc:0.763547\n",
      "[9]\ttrain-auc:0.765845\teval-auc:0.765479\n",
      "[10]\ttrain-auc:0.765878\teval-auc:0.765387\n",
      "[11]\ttrain-auc:0.768155\teval-auc:0.767723\n",
      "[12]\ttrain-auc:0.769464\teval-auc:0.769084\n",
      "[13]\ttrain-auc:0.769999\teval-auc:0.769578\n",
      "[14]\ttrain-auc:0.772055\teval-auc:0.771668\n",
      "[15]\ttrain-auc:0.772509\teval-auc:0.772112\n",
      "[16]\ttrain-auc:0.773249\teval-auc:0.772866\n",
      "[17]\ttrain-auc:0.773723\teval-auc:0.773329\n",
      "[18]\ttrain-auc:0.774321\teval-auc:0.773899\n",
      "[19]\ttrain-auc:0.774609\teval-auc:0.774183\n",
      "[20]\ttrain-auc:0.774855\teval-auc:0.774390\n",
      "[21]\ttrain-auc:0.775263\teval-auc:0.774805\n",
      "[22]\ttrain-auc:0.776163\teval-auc:0.775676\n",
      "[23]\ttrain-auc:0.776646\teval-auc:0.776141\n",
      "[24]\ttrain-auc:0.777081\teval-auc:0.776612\n",
      "[25]\ttrain-auc:0.777541\teval-auc:0.777076\n",
      "[26]\ttrain-auc:0.778464\teval-auc:0.778053\n",
      "[27]\ttrain-auc:0.778636\teval-auc:0.778229\n",
      "[28]\ttrain-auc:0.779128\teval-auc:0.778747\n",
      "[29]\ttrain-auc:0.780650\teval-auc:0.780209\n",
      "[30]\ttrain-auc:0.781345\teval-auc:0.780880\n",
      "[31]\ttrain-auc:0.782253\teval-auc:0.781811\n",
      "[32]\ttrain-auc:0.782877\teval-auc:0.782421\n",
      "[33]\ttrain-auc:0.784173\teval-auc:0.783713\n",
      "[34]\ttrain-auc:0.784796\teval-auc:0.784351\n",
      "[35]\ttrain-auc:0.785391\teval-auc:0.784913\n"
     ]
    }
   ],
   "source": [
    "train, test, features = read_test_train()\n",
    "test_prediction, score = run_default_test(train, test, features, 'isDuplicate')\n",
    "print('Real score = {}'.format(score))\n",
    "create_submission(score, test, test_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
