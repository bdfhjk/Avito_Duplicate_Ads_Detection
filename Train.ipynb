{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy as gp\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "from ml_metrics import auc\n",
    "from operator import itemgetter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "random.seed(4029861075L)\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n",
    "\n",
    "def print_features_importance(imp):\n",
    "    for i in range(len(imp)):\n",
    "        print(\"# \" + str(imp[i][1]))\n",
    "        print('output.remove(\\'' + imp[i][0] + '\\')')\n",
    "\n",
    "\n",
    "def run_default_test(train, test, features, target, random_state=963254170L, create_submission=False):\n",
    "    eta = 0.5\n",
    "    max_depth = 5\n",
    "    subsample = 0.8\n",
    "    colsample_bytree = 0.8\n",
    "    start_time = time.time()\n",
    "    \n",
    "    folds = os.listdir(\"folds\")\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state\n",
    "    }\n",
    "    num_boost_round = 50\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.1\n",
    "    \n",
    "    if not create_submission:\n",
    "        scores = {k: 0 for k in folds}\n",
    "\n",
    "        for fold in folds:\n",
    "\n",
    "            foldnp = np.loadtxt('folds/' + fold, dtype=np.bool)\n",
    "\n",
    "            X_train, X_valid = train[~foldnp], train[foldnp]\n",
    "            # X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "            y_train = X_train[target]\n",
    "            y_valid = X_valid[target]\n",
    "            dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "            dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "            watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "            gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "            print(\"Validating...\")\n",
    "            check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_ntree_limit)\n",
    "            # Use the same metric as kaggle instead of sklearn's one.\n",
    "            # score = roc_auc_score(X_valid[target].values, check)\n",
    "            score = auc(X_valid[target].values, check)\n",
    "            scores[fold] = score\n",
    "            print('FOLD: ' + fold)\n",
    "            print('Check error value: {:.6f}'.format(score))\n",
    "\n",
    "            imp = get_importance(gbm, features)\n",
    "            print('Importance array: ', imp)\n",
    "        \n",
    "        print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "        return scores\n",
    "    else:\n",
    "\n",
    "        print(\"Train on whole set\")\n",
    "        dtrain_full = xgb.DMatrix(train[features], train[target])\n",
    "        gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "        print(\"Predict test set...\")\n",
    "        test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_ntree_limit)\n",
    "\n",
    "        \n",
    "        print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "        return test_prediction.tolist()\n",
    "\n",
    "\n",
    "def create_submission(prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('id,probability\\n')\n",
    "    total = 0\n",
    "    for id in test['id']:\n",
    "        str1 = str(id) + ',' + str(prediction[total])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n",
    "\n",
    "    # print('Creating zip-file...')\n",
    "    # z = zipfile.ZipFile(sub_file + \".zip\", \"w\", zipfile.ZIP_DEFLATED)\n",
    "    # z.write(sub_file)\n",
    "    # z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values)\n",
    "    testval = list(test.columns.values)\n",
    "    output = intersect(trainval, testval)\n",
    "    output.remove('itemID_1')\n",
    "    output.remove('itemID_2')\n",
    "    return output\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "def read_test_train():\n",
    "    \n",
    "    # A version without preprocessing\n",
    "\n",
    "    train = pd.read_csv('input/train_merged.csv')\n",
    "    test = pd.read_csv('input/test_merged.csv')\n",
    "    \n",
    "    features = get_features(train, test)\n",
    "    return train, test, features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of train: ', 2991396)\n",
      "('Length of test: ', 1044196)\n",
      "Features [28]: ['Unnamed: 0', 'categoryID_1', 'categoryID_2', 'categoryID_same', 'distance', 'lat_1', 'lat_2', 'lat_same', 'len_attrsJSON', 'len_description', 'len_title', 'locationID_1', 'locationID_2', 'locationID_same', 'lon_1', 'lon_2', 'lon_same', 'metroID_1', 'metroID_2', 'metroID_same', 'parentCategoryID_1', 'parentCategoryID_2', 'price_1', 'price_2', 'price_same', 'regionID_1', 'regionID_2', 'regionID_same']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train, test, features = read_test_train()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = run_default_test(train, test, features, 'isDuplicate', False)\n",
    "print(scores)\n",
    "print('Real score = {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = run_default_test(train, test, features, 'isDuplicate', True)\n",
    "create_submission(test_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
