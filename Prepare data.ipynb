{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy as gp\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values)\n",
    "    testval = list(test.columns.values)\n",
    "    output = intersect(trainval, testval)\n",
    "    output.remove('itemID_1')\n",
    "    output.remove('itemID_2')\n",
    "    return output\n",
    "\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prep_dataset(is_train, dataset_pairs_path, dataset_info_path, tfidfs_description_path, tfidfs_title_path):\n",
    "    start_time = time.time()\n",
    "\n",
    "    types1 = {\n",
    "        'itemID_1': np.dtype(int),\n",
    "        'itemID_2': np.dtype(int),\n",
    "        'isDuplicate': np.dtype(int),\n",
    "        'generationMethod': np.dtype(int),\n",
    "    }\n",
    "\n",
    "    types2 = {\n",
    "        'itemID': np.dtype(int),\n",
    "        'categoryID': np.dtype(int),\n",
    "        'title': np.dtype(str),\n",
    "        'description': np.dtype(str),\n",
    "        'images_array': np.dtype(str),\n",
    "        'attrsJSON': np.dtype(str),\n",
    "        'price': np.dtype(float),\n",
    "        'locationID': np.dtype(int),\n",
    "        'metroID': np.dtype(float),\n",
    "        'lat': np.dtype(float),\n",
    "        'lon': np.dtype(float),\n",
    "    }\n",
    "\n",
    "    pairs = pd.read_csv(dataset_pairs_path, dtype=types1)\n",
    "\n",
    "    # Add 'id' column for easy merge\n",
    "    items = pd.read_csv(dataset_info_path, dtype=types2)\n",
    "    items.fillna(-1, inplace=True)\n",
    "    location = pd.read_csv(\"input/Location.csv\")\n",
    "    category = pd.read_csv(\"input/Category.csv\")\n",
    "\n",
    "    train = pairs\n",
    "    \n",
    "    if is_train:\n",
    "        train = train.drop(['generationMethod'], axis=1)\n",
    "\n",
    "    print('Add text features...')\n",
    "    # Dodaj różnice i sumy\n",
    "    #train['len_title'] = items['title'].str.len()\n",
    "    #train['len_description'] = items['description'].str.len()\n",
    "\n",
    "    print('Merge item 1...')\n",
    "    item1 = items[['itemID', 'categoryID', 'description', 'price', 'locationID', 'metroID', 'lat', 'lon']]\n",
    "    item1 = pd.merge(item1, category, how='left', on='categoryID', left_index=True)\n",
    "    item1 = pd.merge(item1, location, how='left', on='locationID', left_index=True)\n",
    "\n",
    "    item1 = item1.rename(\n",
    "        columns={\n",
    "            'itemID': 'itemID_1',\n",
    "            'categoryID': 'categoryID_1',\n",
    "            'description': 'description_1',\n",
    "            'parentCategoryID': 'parentCategoryID_1',\n",
    "            'price': 'price_1',\n",
    "            'locationID': 'locationID_1',\n",
    "            'regionID': 'regionID_1',\n",
    "            'metroID': 'metroID_1',\n",
    "            'lat': 'lat_1',\n",
    "            'lon': 'lon_1'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add item 1 data\n",
    "    train = pd.merge(train, item1, how='left', on='itemID_1', left_index=True)\n",
    "\n",
    "    print('Merge item 2...')\n",
    "    item2 = items[['itemID', 'categoryID', 'description', 'price', 'locationID', 'metroID', 'lat', 'lon']]\n",
    "    item2 = pd.merge(item2, category, how='left', on='categoryID', left_index=True)\n",
    "    item2 = pd.merge(item2, location, how='left', on='locationID', left_index=True)\n",
    "\n",
    "    item2 = item2.rename(\n",
    "        columns={\n",
    "            'itemID': 'itemID_2',\n",
    "            'categoryID': 'categoryID_2',\n",
    "            'description': 'description_2',\n",
    "            'parentCategoryID': 'parentCategoryID_2',\n",
    "            'price': 'price_2',\n",
    "            'locationID': 'locationID_2',\n",
    "            'regionID': 'regionID_2',\n",
    "            'metroID': 'metroID_2',\n",
    "            'lat': 'lat_2',\n",
    "            'lon': 'lon_2'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add item 2 data\n",
    "    train = pd.merge(train, item2, how='left', on='itemID_2', left_index=True)\n",
    "\n",
    "    # Create same arrays\n",
    "    print('Create same arrays')\n",
    "\n",
    "    \n",
    "    # Create distance\n",
    "    def geopydistance(a, b, c, d):\n",
    "        p1 = gp.Point([a, b])\n",
    "        p2 = gp.Point([c, d])\n",
    "        return vincenty(p1,p2).kilometers\n",
    "    vecfunc = np.vectorize(geopydistance)\n",
    "    \n",
    "    train['distance'] = vecfunc(train['lat_1'], train['lon_1'], train['lat_2'], train['lon_2'])\n",
    "\n",
    "    train['price_abs'] = np.true_divide(np.abs(np.subtract(train['price_1'], train['price_2'])),\n",
    "                                        np.add(train['price_1'], train['price_2']))\n",
    "    train['price_sum'] = np.add(train['price_1'], train['price_2'])\n",
    "    train['price_diff'] = np.abs(np.subtract(train['price_1'], train['price_2']))\n",
    "    train['lat_diff'] = np.abs(np.subtract(train['lat_1'], train['lat_2']))\n",
    "    train['lon_diff'] = np.abs(np.subtract(train['lon_1'], train['lon_2']))\n",
    "    train['lat_sum'] = np.add(train['lat_1'], train['lat_2'])       \n",
    "    train['lon_sum'] = np.add(train['lon_1'], train['lon_2'])   \n",
    "                               \n",
    "    # Create categories!\n",
    "    def same(a,b):\n",
    "        if a == b:\n",
    "            return a\n",
    "        else:\n",
    "            if isinstance(a, str):\n",
    "                return \"different\"\n",
    "            else:\n",
    "                return -1.0\n",
    "    vecfunc = np.vectorize(same)\n",
    "                               \n",
    "    train['category'] = vecfunc(train['categoryID_1'], train['categoryID_2'])\n",
    "    train['metro'] = vecfunc(train['metroID_1'], train['metroID_2'])\n",
    "    train['region'] = vecfunc(train['regionID_1'], train['regionID_2'])\n",
    "    train['location'] = vecfunc(train['locationID_1'], train['locationID_2'])\n",
    "    train['lat_same'] = vecfunc(train['lat_1'], train['lat_2'])\n",
    "    train['lon_same'] = vecfunc(train['lon_1'], train['lon_2'])\n",
    "          \n",
    "    # Categories\n",
    "\n",
    "    # Add tfidfs\n",
    "    train['title_dist'] = np.loadtxt(tfidfs_title_path, usecols=(1,), delimiter=\",\")\n",
    "    train['description_dist'] = np.loadtxt(tfidfs_description_path, usecols=(1,), delimiter=\",\")\n",
    "    \n",
    "    print('Create train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    \n",
    "    # ITEM IDS ARE REMOVED LATER\n",
    "    train.drop(['description_1', \n",
    "                'description_2',\n",
    "                'price_1',\n",
    "                'price_2',\n",
    "                'lat_1',\n",
    "                'lat_2',\n",
    "                'lon_1',\n",
    "                'lon_2',\n",
    "                'metroID_1',\n",
    "                'metroID_2',\n",
    "                'regionID_1',\n",
    "                'regionID_2',\n",
    "                'locationID_2',\n",
    "                'locationID_1',\n",
    "                'parentCategoryID_2',\n",
    "                'parentCategoryID_1',\n",
    "                'categoryID_2',\n",
    "                'categoryID_1',\n",
    "                ], axis=1, inplace=True)\n",
    "    return train\n",
    "\n",
    "def read_test_train(from_disk=False):\n",
    "    \n",
    "    train = prep_dataset(True, \"input/ItemPairs_train.csv\", \"input/ItemInfo_train.csv\",\n",
    "                               \"similarities/train_description_stopwords_cosine.csv\",\n",
    "                               \"similarities/train_title_stopwords_cosine.csv\")\n",
    "    train.fillna(-1, inplace=True)\n",
    "    train.to_csv('input/train_merged.csv')\n",
    "\n",
    "\n",
    "    test = prep_dataset(False, \"input/ItemPairs_test.csv\", \"input/ItemInfo_test.csv\",\n",
    "                               \"similarities/test_description_stopwords_cosine.csv\",\n",
    "                               \"similarities/test_title_stopwords_cosine.csv\")\n",
    "    test.fillna(-1, inplace=True)\n",
    "    test.to_csv('input/test_merged.csv')\n",
    "\n",
    "    features = get_features(train, test)\n",
    "    return train, test, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add text features...\n",
      "Merge item 1...\n",
      "Merge item 2...\n",
      "Create same arrays\n",
      "Create train data time: 113.81 seconds\n",
      "Add text features...\n",
      "Merge item 1...\n",
      "Merge item 2...\n",
      "Create same arrays\n",
      "Create train data time: 47.98 seconds\n",
      "('Length of train: ', 2991396)\n",
      "('Length of test: ', 1044196)\n",
      "Features [16]: ['category', 'description_dist', 'distance', 'lat_diff', 'lat_same', 'lat_sum', 'location', 'lon_diff', 'lon_same', 'lon_sum', 'metro', 'price_abs', 'price_diff', 'price_sum', 'region', 'title_dist']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train, test, features = read_test_train()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
