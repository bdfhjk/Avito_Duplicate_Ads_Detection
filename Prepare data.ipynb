{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy as gp\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values)\n",
    "    testval = list(test.columns.values)\n",
    "    output = intersect(trainval, testval)\n",
    "    output.remove('itemID_1')\n",
    "    output.remove('itemID_2')\n",
    "    return output\n",
    "\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prep_dataset(is_train, dataset_pairs_path, dataset_info_path):\n",
    "    start_time = time.time()\n",
    "\n",
    "    types1 = {\n",
    "        'itemID_1': np.dtype(int),\n",
    "        'itemID_2': np.dtype(int),\n",
    "        'isDuplicate': np.dtype(int),\n",
    "        'generationMethod': np.dtype(int),\n",
    "    }\n",
    "\n",
    "    types2 = {\n",
    "        'itemID': np.dtype(int),\n",
    "        'categoryID': np.dtype(int),\n",
    "        'title': np.dtype(str),\n",
    "        'description': np.dtype(str),\n",
    "        'images_array': np.dtype(str),\n",
    "        'attrsJSON': np.dtype(str),\n",
    "        'price': np.dtype(float),\n",
    "        'locationID': np.dtype(int),\n",
    "        'metroID': np.dtype(float),\n",
    "        'lat': np.dtype(float),\n",
    "        'lon': np.dtype(float),\n",
    "    }\n",
    "\n",
    "    pairs = pd.read_csv(dataset_pairs_path, dtype=types1)\n",
    "\n",
    "    # Add 'id' column for easy merge\n",
    "    items = pd.read_csv(dataset_info_path, dtype=types2)\n",
    "    items.fillna(-1, inplace=True)\n",
    "    location = pd.read_csv(\"input/Location.csv\")\n",
    "    category = pd.read_csv(\"input/Category.csv\")\n",
    "\n",
    "    train = pairs\n",
    "    \n",
    "    if is_train:\n",
    "        train = train.drop(['generationMethod'], axis=1)\n",
    "\n",
    "    print('Add text features...')\n",
    "    train['len_title'] = items['title'].str.len()\n",
    "    train['len_description'] = items['description'].str.len()\n",
    "    train['len_attrsJSON'] = items['attrsJSON'].str.len()\n",
    "\n",
    "    print('Merge item 1...')\n",
    "    item1 = items[['itemID', 'categoryID', 'description', 'price', 'locationID', 'metroID', 'lat', 'lon']]\n",
    "    item1 = pd.merge(item1, category, how='left', on='categoryID', left_index=True)\n",
    "    item1 = pd.merge(item1, location, how='left', on='locationID', left_index=True)\n",
    "\n",
    "    item1 = item1.rename(\n",
    "        columns={\n",
    "            'itemID': 'itemID_1',\n",
    "            'categoryID': 'categoryID_1',\n",
    "            'description': 'description_1',\n",
    "            'parentCategoryID': 'parentCategoryID_1',\n",
    "            'price': 'price_1',\n",
    "            'locationID': 'locationID_1',\n",
    "            'regionID': 'regionID_1',\n",
    "            'metroID': 'metroID_1',\n",
    "            'lat': 'lat_1',\n",
    "            'lon': 'lon_1'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add item 1 data\n",
    "    train = pd.merge(train, item1, how='left', on='itemID_1', left_index=True)\n",
    "\n",
    "    print('Merge item 2...')\n",
    "    item2 = items[['itemID', 'categoryID', 'description', 'price', 'locationID', 'metroID', 'lat', 'lon']]\n",
    "    item2 = pd.merge(item2, category, how='left', on='categoryID', left_index=True)\n",
    "    item2 = pd.merge(item2, location, how='left', on='locationID', left_index=True)\n",
    "\n",
    "    item2 = item2.rename(\n",
    "        columns={\n",
    "            'itemID': 'itemID_2',\n",
    "            'categoryID': 'categoryID_2',\n",
    "            'description': 'description_2',\n",
    "            'parentCategoryID': 'parentCategoryID_2',\n",
    "            'price': 'price_2',\n",
    "            'locationID': 'locationID_2',\n",
    "            'regionID': 'regionID_2',\n",
    "            'metroID': 'metroID_2',\n",
    "            'lat': 'lat_2',\n",
    "            'lon': 'lon_2'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add item 2 data\n",
    "    train = pd.merge(train, item2, how='left', on='itemID_2', left_index=True)\n",
    "\n",
    "    # Create same arrays\n",
    "    print('Create same arrays')\n",
    "    train['price_same'] = np.equal(train['price_1'], train['price_2']).astype(np.int32)\n",
    "    train['locationID_same'] = np.equal(train['locationID_1'], train['locationID_2']).astype(np.int32)\n",
    "    train['categoryID_same'] = np.equal(train['categoryID_1'], train['categoryID_2']).astype(np.int32)\n",
    "    train['regionID_same'] = np.equal(train['regionID_1'], train['regionID_2']).astype(np.int32)\n",
    "    train['metroID_same'] = np.equal(train['metroID_1'], train['metroID_2']).astype(np.int32)\n",
    "    train['lat_same'] = np.equal(train['lat_1'], train['lat_2']).astype(np.int32)\n",
    "    train['lon_same'] = np.equal(train['lon_1'], train['lon_2']).astype(np.int32)\n",
    "    \n",
    "    # Create distance\n",
    "    def geopydistance(a, b, c, d):\n",
    "        p1 = gp.Point([a, b])\n",
    "        p2 = gp.Point([c, d])\n",
    "        return vincenty(p1,p2).kilometers\n",
    "    vecfunc = np.vectorize(geopydistance)\n",
    "    \n",
    "    train['distance'] = vecfunc(train['lat_1'], train['lon_1'], train['lat_2'], train['lon_2'])\n",
    "    \n",
    "    # Create description distance\n",
    "    def description_distance(a, b):\n",
    "        try:\n",
    "            asp = a.split()\n",
    "            bsp = b.split()\n",
    "            same_words = 0\n",
    "            for w1 in asp:\n",
    "                for w2 in bsp:\n",
    "                    if w1 == w2:\n",
    "                        same_words = same_words + 1\n",
    "            return same_words\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    vecfunc = np.vectorize(description_distance)\n",
    "    \n",
    "    train['description_distance'] = vecfunc(train['description_1'], train['description_2'])\n",
    "    \n",
    "    #tfidf = TfidfVectorizer(stop_words = stopwords.words('russian')).fit_transform([train['description_1'].str, train['description_2'].str])\n",
    "    #cosine_similarities = linear_kernel(tfidf[0], tfidf[1]).flatten()    \n",
    "    #train['description_diff'] = cosine_similarities[0]\n",
    "    \n",
    "    print('Create train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    train.drop(['description_1', \n",
    "                'description_2'], axis=1, inplace=True)\n",
    "    return train\n",
    "\n",
    "def read_test_train(from_disk=False):\n",
    "    \n",
    "    train = prep_dataset(True, \"input/ItemPairs_train.csv\", \"input/ItemInfo_train.csv\")\n",
    "    train.fillna(-1, inplace=True)\n",
    "    train.to_csv('input/train_merged.csv')\n",
    "\n",
    "\n",
    "    test = prep_dataset(False, \"input/ItemPairs_test.csv\", \"input/ItemInfo_test.csv\")\n",
    "    test.fillna(-1, inplace=True)\n",
    "    test.to_csv('input/test_merged.csv')\n",
    "\n",
    "    features = get_features(train, test)\n",
    "    return train, test, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add text features...\n",
      "Merge item 1...\n",
      "Merge item 2...\n",
      "Create same arrays\n",
      "Create train data time: 401.69 seconds\n",
      "Add text features...\n",
      "Merge item 1...\n",
      "Merge item 2...\n",
      "Create same arrays\n",
      "Create train data time: 116.81 seconds\n",
      "('Length of train: ', 2991396)\n",
      "('Length of test: ', 1044196)\n",
      "Features [28]: ['categoryID_1', 'categoryID_2', 'categoryID_same', 'description_distance', 'distance', 'lat_1', 'lat_2', 'lat_same', 'len_attrsJSON', 'len_description', 'len_title', 'locationID_1', 'locationID_2', 'locationID_same', 'lon_1', 'lon_2', 'lon_same', 'metroID_1', 'metroID_2', 'metroID_same', 'parentCategoryID_1', 'parentCategoryID_2', 'price_1', 'price_2', 'price_same', 'regionID_1', 'regionID_2', 'regionID_same']\n"
     ]
    }
   ],
   "source": [
    "train, test, features = read_test_train()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
